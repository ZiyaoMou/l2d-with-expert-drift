{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqpaVy5IRwJM"
   },
   "source": [
    "# Hate Speech and Offensive Language Detection\n",
    "This notebook runs our experiments on the Hate Speech and Offensive Language Detection tweet dataset.\n",
    "WARNING: dataset contains offensive language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmjrIyVlbO44"
   },
   "source": [
    "##  AAE detection model\n",
    "As described in our paper, we use the model from https://github.com/slanglab/twitteraae to detect the dialect of each tweet, we only need the model files from the repo which we have conveniently copied in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Uk4UtaGhbbxt",
    "outputId": "87575ecf-058f-4db2-ac66-5781ed095e98"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import time\n",
    "import random\n",
    "vocabfile = \"/home/zmou1/scratchenalisn1/ziyao/l2d-data/hatespeech/twitteraae/model/model_vocab.txt\" # change path if needed, path inside twitteraae repo is twitteraae/model/model_vocab.txt\n",
    "modelfile = \"/home/zmou1/scratchenalisn1/ziyao/l2d-data/hatespeech/twitteraae/model/model_count_table.txt\" # change path if needed, path inside twitteraae repo is twitteraae/model/model_vocab.txt\n",
    "\n",
    "# the following functions are copied from twitteraae for convenience\n",
    "K=0; wordprobs=None; w2num=None\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Idempotent\"\"\"\n",
    "    global vocab,w2num,N_wk,N_k,wordprobs,N_w,K, modelfile,vocabfile\n",
    "    if wordprobs is not None:\n",
    "        # assume already loaded\n",
    "        return\n",
    "\n",
    "    N_wk = np.loadtxt(modelfile)\n",
    "    N_w = N_wk.sum(1)\n",
    "    N_k = N_wk.sum(0)\n",
    "    K = len(N_k)\n",
    "    wordprobs = (N_wk + 1) / N_k\n",
    "\n",
    "    vocab = [L.split(\"\\t\")[-1].strip() for L in open(vocabfile,encoding=\"utf8\")]\n",
    "    w2num = {w:i for i,w in enumerate(vocab)}\n",
    "    assert len(vocab) == N_wk.shape[0]\n",
    "\n",
    "def infer_cvb0(invocab_tokens, alpha, numpasses):\n",
    "    global K,wordprobs,w2num\n",
    "    doclen = len(invocab_tokens)\n",
    "\n",
    "    # initialize with likelihoods\n",
    "    Qs = np.zeros((doclen, K))\n",
    "    for i in range(0,doclen):\n",
    "        w = invocab_tokens[i]\n",
    "        Qs[i,:] = wordprobs[w2num[w],:]\n",
    "        Qs[i,:] /= Qs[i,:].sum()\n",
    "    lik = Qs.copy()  # pertoken normalized but proportionally the same for inference\n",
    "\n",
    "    Q_k = Qs.sum(0)\n",
    "    for itr in range(1,numpasses):\n",
    "        # print \"cvb0 iter\", itr\n",
    "        for i in range(0,doclen):\n",
    "            Q_k -= Qs[i,:]\n",
    "            Qs[i,:] = lik[i,:] * (Q_k + alpha)\n",
    "            Qs[i,:] /= Qs[i,:].sum()\n",
    "            Q_k += Qs[i,:]\n",
    "\n",
    "    Q_k /= Q_k.sum()\n",
    "    return Q_k\n",
    "\n",
    "def predict_lang(tokens, alpha=1, numpasses=5, thresh1=1, thresh2=0.2):\n",
    "    invocab_tokens = [w.lower() for w in tokens if w.lower() in w2num]\n",
    "    # check that at least xx tokens are in vocabulary\n",
    "    if len(invocab_tokens) < thresh1:\n",
    "        return None  \n",
    "    # check that at least yy% of tokens are in vocabulary\n",
    "    elif len(invocab_tokens) / len(tokens) < thresh2:\n",
    "        return None\n",
    "    else:\n",
    "        posterior = infer_cvb0(invocab_tokens, alpha=alpha, numpasses=numpasses)\n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the twitteraae model for detection\n",
    "load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_path = \"/home/zmou1/scratchenalisn1/ziyao/l2d-cog/hatespeech/data/labeled_data.csv\" # change path if needed\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.long, sequential=False, use_vocab=False)\n",
    "EXPERT = data.LabelField(dtype = torch.long,  sequential=False, use_vocab=False)\n",
    "GROUP = data.LabelField(dtype = torch.long, sequential=False, use_vocab=False)\n",
    "EXPERTLABEL = data.LabelField(dtype = torch.long, sequential=False, use_vocab=False)\n",
    "\n",
    "fields = [(None, None),(None, None),('expertlabel', EXPERTLABEL),('group', GROUP),('expert', EXPERT),\n",
    "          ('label', LABEL), ('text', TEXT)]\n",
    "\n",
    "train_data_orig = data.TabularDataset.splits(\n",
    "                                        path = '',\n",
    "                                        train = labeled_data_path,\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKn4AL_cRwJo"
   },
   "source": [
    "We load the dataset 'labeled_data.csv', available at https://github.com/t-davidson/hate-speech-and-offensive-language, for convenience we copy it to this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf20Ut32oPCd"
   },
   "source": [
    "Augment data with expert predictions and demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "pYfTDftioZBu",
    "outputId": "8e991090-054a-440a-ef1c-21d98b3996fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing tweet: ['@Fulf_ShawnFulf', 'peckerwood']\n",
      "error processing tweet: ['GA', 'Charlie', '@Charlie4927', '@sholzbee', '@DorisTafoya1', '@cat_lmbo', '@Jagauress', '@Walter_lars', '@lynnemrnp', '@AmyMek', '@Justin_Awe']\n",
      "error processing tweet: ['RT', '@cenopant', ':', '(', 'she)s', '\\n', 'bro(was)ken', '\\n', 'bec(a)use', '\\n', 's(side)he', '\\n', 'beli(hoe)ved']\n"
     ]
    }
   ],
   "source": [
    "# build expert data\n",
    "all_data = train_data_orig[0]\n",
    "\n",
    "p = 0.75 # expert probability of being correct for AA tweeet\n",
    "q = 0.9 # expert probability of being correct for AA tweeet\n",
    "\n",
    "# tracker variables for statistics\n",
    "sum = 0\n",
    "total = 0\n",
    "i = 0\n",
    "aa_frac = 0\n",
    "for example in all_data:\n",
    "    lang = predict_lang(vars(example)['text'])\n",
    "    aa = 0\n",
    "    try:\n",
    "        if lang[0] >= 0.5:\n",
    "            aa = 1\n",
    "    except:\n",
    "        print(\"error processing tweet: \"+str(vars(example)['text']))\n",
    "    label = vars(example)['label']\n",
    "    exp = 0 # 0: expert wrong, 1: expert is right\n",
    "    exp_label = 0\n",
    "    if aa == 1: # if tweet is african american\n",
    "\n",
    "        coin = np.random.binomial(1,p)\n",
    "        if coin:\n",
    "            exp =1 \n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    else:\n",
    "        coin = np.random.binomial(1,q)\n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    #if label =='2' : # 2: neither, 1: offensive, 0: hate speech\n",
    "    #    aa = 1\n",
    "    vars(all_data[i])['expertlabel'] = exp_label\n",
    "    vars(all_data[i])['group'] = str(aa)\n",
    "    vars(all_data[i])['expert'] = exp\n",
    "    aa_frac += aa\n",
    "    i += 1\n",
    "    total +=1\n",
    "    sum += exp\n",
    "#print(sum/total)\n",
    "#print(aa_frac/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data for Pytorch and vectorize, this requires the glove.6b.100d embeddings which will be downloaded (862mb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT vocab size = 25002\n",
      "PAD in stoi?      True\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(all_data)\n",
    "EXPERT.build_vocab(all_data)\n",
    "GROUP.build_vocab(all_data)\n",
    "EXPERTLABEL.build_vocab(all_data)\n",
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(all_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "print(\"TEXT vocab size =\", len(TEXT.vocab))\n",
    "print(\"PAD in stoi?     \", \"<pad>\" in TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLKxaqpIRwJ4"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data  = all_data.split(split_ratio=[0.6,0.1,0.3])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14870\n",
      "dict_keys(['expertlabel', 'group', 'expert', 'label', 'text'])\n",
      "text tokens: ['RT', '@JoeBudden', ':', 'If', 'u', 'can&#8217;t', 'deal', 'w', 'what', 'we', 'go', 'thru&#8230', ';', '.', 'Then', 'I', 'got', 'bitches', 'lined', 'up', ',', 'I', 'got', 'an', 'ego', 'too', '.']\n",
      "label: 1\n",
      "expert: 1\n",
      "group: 1\n",
      "expertlabel: 1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "ex = train_data.examples[0]\n",
    "print(vars(ex).keys())\n",
    "print(\"text tokens:\", ex.text)\n",
    "print(\"label:\", ex.label) \n",
    "print(\"expert:\", ex.expert)\n",
    "print(\"group:\", ex.group)\n",
    "print(\"expertlabel:\", ex.expertlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is of two parts:\n",
    "1) the first part goes through our method and baselines to get results\n",
    "2) the second combines all models to get std and confidence intervals, but need to go through the first part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZLZocE7ggnm"
   },
   "source": [
    "# Build model\n",
    "Model definitions for sentiment analysis adapted from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMT9UoiigZhS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "class CNN_rej(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding_rej = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs_rej = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc_rej = nn.Linear(len(filter_sizes) * n_filters, 1)\n",
    "        \n",
    "        self.dropout_rej = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        embedded_rej = self.\n",
    "        \n",
    "        \n",
    "        \n",
    "        (text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded_rej = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_rej = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs_rej]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled_rej = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat_rej = self.dropout_rej(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        out_rej = self.fc_rej(cat_rej)\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        out =  torch.cat((out, out_rej), 1)\n",
    "\n",
    "        out = self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100 # fixed\n",
    "N_FILTERS = 300 # hyperparameterr\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 4\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model = CNN_rej(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 3, DROPOUT, PAD_IDX)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hs2N0LRbRwKb"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHXr-a2ARwKf"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usU7JU75RwKp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "def reject_CrossEntropyLoss(outputs, m, labels, m2, n_classes):\n",
    "    '''\n",
    "    The L_{CE} loss implementation for hatespeech, identical to CIFAR implementation\n",
    "    ----\n",
    "    outputs: network outputs\n",
    "    m: cost of deferring to expert cost of classifier predicting (I_{m =y})\n",
    "    labels: target\n",
    "    m2:  cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "    n_classes: number of classes\n",
    "    '''\n",
    "    batch_size = outputs.size()[0]            # batch_size\n",
    "    rc = [n_classes] * batch_size\n",
    "    rc = torch.tensor(rc)\n",
    "    outputs =  -m*torch.log2( outputs[range(batch_size), rc]) - m2*torch.log2(outputs[range(batch_size), labels])   # pick the values corresponding to the labels\n",
    "    return torch.sum(outputs)/batch_size\n",
    "\n",
    "def train_reject(model, iterator, optimizer,alpha):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text)\n",
    "        batch_size = predictions.size()[0]\n",
    "        # get expert predictions and costs \n",
    "        m = (batch.expert)*1.0 # expert agreement with label: I_{m=y}\n",
    "        m2 = [1] * batch_size\n",
    "        m2 = torch.tensor(m2)\n",
    "        for j in range (0,batch_size):\n",
    "            exp = m[j].item()\n",
    "            if exp:\n",
    "                m2[j] = alpha\n",
    "            else:\n",
    "                m2[j] = 1\n",
    "\n",
    "        m2 = m2.to(device)\n",
    "\n",
    "        loss = reject_CrossEntropyLoss(predictions, m, batch.label, m2, 3)\n",
    "\n",
    "        acc = categorical_accuracy(predictions, batch.label.to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate_reject(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)\n",
    "            batch_size = predictions.size()[0]            # batch_size\n",
    "            m = batch.expert\n",
    "            m2 = [1] * batch_size\n",
    "            m2 = torch.tensor(m2)\n",
    "            m2 = m2.to(device)\n",
    "            loss = reject_CrossEntropyLoss(predictions, m, batch.label, m2, 3)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbfpfCHA0UNe"
   },
   "outputs": [],
   "source": [
    "def metrics_print(net, loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs = net(data.text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = (predicted[i].item() == 3)\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys += data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "def metrics_print_fairness(net, loader):\n",
    "    net.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs = net(data.text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = (predicted[i].item() == 3)\n",
    "                prediction = 0\n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "\n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvNc3f0YRwK-"
   },
   "source": [
    "Train the model by validation over alpha in [0,1] with steps of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "colab_type": "code",
    "id": "IapphlTjRwLD",
    "outputId": "66727958-0c5a-4f5d-e9ed-d16dc76cec25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmou1/scratchenalisn1/ziyao/anaconda3/envs/hs_legacy/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '1 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.57811186288964, 'classifier accuracy': 99.9900009999, 'alone classifier': 0.0}\n",
      "{'coverage': '44 out of2478', 'system accuracy': 84.78611783696529, 'expert accuracy': 84.67542443094294, 'classifier accuracy': 90.90888429799023, 'alone classifier': 0.0}\n",
      "{'coverage': '20 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.54026976889587, 'classifier accuracy': 89.99955000224999, 'alone classifier': 0.0}\n",
      "{'coverage': '93 out of2478', 'system accuracy': 85.02824858757062, 'expert accuracy': 84.73793838675569, 'classifier accuracy': 92.47301884621629, 'alone classifier': 0.0}\n",
      "{'coverage': '93 out of2478', 'system accuracy': 85.02824858757062, 'expert accuracy': 84.73793838675569, 'classifier accuracy': 92.47301884621629, 'alone classifier': 0.0}\n",
      "[3.7530266343825667, 85.02824858757062, 84.73793838675569, 92.47301884621629]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '24 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.51507053666907, 'classifier accuracy': 91.66628472381365, 'alone classifier': 0.0}\n",
      "{'coverage': '114 out of2478', 'system accuracy': 85.14931396287328, 'expert accuracy': 84.64466288962242, 'classifier accuracy': 95.61395121583226, 'alone classifier': 0.0}\n",
      "{'coverage': '59 out of2478', 'system accuracy': 84.82647296206618, 'expert accuracy': 84.66307691913379, 'classifier accuracy': 91.52526860123966, 'alone classifier': 0.0}\n",
      "{'coverage': '114 out of2478', 'system accuracy': 85.14931396287328, 'expert accuracy': 84.64466288962242, 'classifier accuracy': 95.61395121583226, 'alone classifier': 0.0}\n",
      "[4.600484261501211, 85.14931396287328, 84.64466288962242, 95.61395121583226]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '34 out of2478', 'system accuracy': 84.70540758676351, 'expert accuracy': 84.57446116411938, 'classifier accuracy': 94.11737024302869, 'alone classifier': 0.0}\n",
      "{'coverage': '68 out of2478', 'system accuracy': 84.78611783696529, 'expert accuracy': 84.64729587989245, 'classifier accuracy': 89.70575043271995, 'alone classifier': 0.0}\n",
      "{'coverage': '73 out of2478', 'system accuracy': 84.90718321226795, 'expert accuracy': 84.69853765500727, 'classifier accuracy': 91.78069619082713, 'alone classifier': 0.0}\n",
      "{'coverage': '269 out of2478', 'system accuracy': 85.87570621468926, 'expert accuracy': 85.19691397040164, 'classifier accuracy': 91.44978013019328, 'alone classifier': 0.0}\n",
      "{'coverage': '269 out of2478', 'system accuracy': 85.87570621468926, 'expert accuracy': 85.19691397040164, 'classifier accuracy': 91.44978013019328, 'alone classifier': 0.0}\n",
      "[10.85552865213882, 85.87570621468926, 85.19691397040164, 91.44978013019328]\n",
      "{'coverage': '2 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.57188331406435, 'classifier accuracy': 99.99500024998748, 'alone classifier': 0.0}\n",
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '64 out of2478', 'system accuracy': 85.02824858757062, 'expert accuracy': 84.87986040763377, 'classifier accuracy': 90.62485839865874, 'alone classifier': 0.0}\n",
      "{'coverage': '55 out of2478', 'system accuracy': 84.94753833736884, 'expert accuracy': 84.7709381121801, 'classifier accuracy': 92.72710413253793, 'alone classifier': 0.0}\n",
      "{'coverage': '66 out of2478', 'system accuracy': 84.78611783696529, 'expert accuracy': 84.74294488035284, 'classifier accuracy': 86.36350550984014, 'alone classifier': 0.0}\n",
      "{'coverage': '64 out of2478', 'system accuracy': 85.02824858757062, 'expert accuracy': 84.87986040763377, 'classifier accuracy': 90.62485839865874, 'alone classifier': 0.0}\n",
      "[2.58272800645682, 85.02824858757062, 84.87986040763377, 90.62485839865874]\n",
      "{'coverage': '5 out of2478', 'system accuracy': 84.50363196125907, 'expert accuracy': 84.55316744414336, 'classifier accuracy': 59.99880002399952, 'alone classifier': 0.0}\n",
      "{'coverage': '1 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.57811186288964, 'classifier accuracy': 99.9900009999, 'alone classifier': 0.0}\n",
      "{'coverage': '42 out of2478', 'system accuracy': 84.90718321226795, 'expert accuracy': 84.77010798274976, 'classifier accuracy': 92.85692176923388, 'alone classifier': 0.0}\n",
      "{'coverage': '45 out of2478', 'system accuracy': 84.54398708635996, 'expert accuracy': 84.50471972834198, 'classifier accuracy': 86.66647407450205, 'alone classifier': 0.0}\n",
      "{'coverage': '221 out of2478', 'system accuracy': 85.67393058918482, 'expert accuracy': 85.0686676944025, 'classifier accuracy': 91.85516205648776, 'alone classifier': 0.0}\n",
      "{'coverage': '221 out of2478', 'system accuracy': 85.67393058918482, 'expert accuracy': 85.0686676944025, 'classifier accuracy': 91.85516205648776, 'alone classifier': 0.0}\n",
      "[8.918482647296207, 85.67393058918482, 85.0686676944025, 91.85516205648776]\n",
      "{'coverage': '3 out of2478', 'system accuracy': 84.54398708635996, 'expert accuracy': 84.5656497320687, 'classifier accuracy': 66.66444451851605, 'alone classifier': 0.0}\n",
      "{'coverage': '6 out of2478', 'system accuracy': 84.54398708635996, 'expert accuracy': 84.5873717971382, 'classifier accuracy': 66.66555557407376, 'alone classifier': 0.0}\n",
      "{'coverage': '48 out of2478', 'system accuracy': 84.90718321226795, 'expert accuracy': 84.85596009415967, 'classifier accuracy': 87.4998177087131, 'alone classifier': 0.0}\n",
      "{'coverage': '101 out of2478', 'system accuracy': 85.14931396287328, 'expert accuracy': 84.77071226161445, 'classifier accuracy': 94.05931281256157, 'alone classifier': 0.0}\n",
      "{'coverage': '197 out of2478', 'system accuracy': 85.55286521388216, 'expert accuracy': 85.00656860968272, 'classifier accuracy': 91.87812595018987, 'alone classifier': 0.0}\n",
      "{'coverage': '197 out of2478', 'system accuracy': 85.55286521388216, 'expert accuracy': 85.00656860968272, 'classifier accuracy': 91.87812595018987, 'alone classifier': 0.0}\n",
      "[7.949959644874899, 85.55286521388216, 85.00656860968272, 91.87812595018987]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '2 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.57188331406435, 'classifier accuracy': 99.99500024998748, 'alone classifier': 0.0}\n",
      "{'coverage': '28 out of2478', 'system accuracy': 84.86682808716706, 'expert accuracy': 84.73468696043372, 'classifier accuracy': 96.42822704204627, 'alone classifier': 0.0}\n",
      "{'coverage': '41 out of2478', 'system accuracy': 84.70540758676351, 'expert accuracy': 84.61222120539834, 'classifier accuracy': 90.24368233248211, 'alone classifier': 0.0}\n",
      "{'coverage': '305 out of2478', 'system accuracy': 85.95641646489103, 'expert accuracy': 85.04371053440308, 'classifier accuracy': 92.45898607902096, 'alone classifier': 0.0}\n",
      "{'coverage': '305 out of2478', 'system accuracy': 85.95641646489103, 'expert accuracy': 85.04371053440308, 'classifier accuracy': 92.45898607902096, 'alone classifier': 0.0}\n",
      "[12.308313155770783, 85.95641646489103, 85.04371053440308, 92.45898607902096]\n",
      "{'coverage': '3 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.5656497320687, 'classifier accuracy': 99.99666677777407, 'alone classifier': 0.0}\n",
      "{'coverage': '92 out of2478', 'system accuracy': 85.0686037126715, 'expert accuracy': 84.82815718121063, 'classifier accuracy': 91.30424858233849, 'alone classifier': 0.0}\n",
      "{'coverage': '10 out of2478', 'system accuracy': 84.54398708635996, 'expert accuracy': 84.6029104859878, 'classifier accuracy': 69.99930000699993, 'alone classifier': 0.0}\n",
      "{'coverage': '43 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 84.59958237375093, 'classifier accuracy': 86.04631152020576, 'alone classifier': 0.0}\n",
      "{'coverage': '150 out of2478', 'system accuracy': 85.02824858757062, 'expert accuracy': 84.79380714829836, 'classifier accuracy': 88.66660755559496, 'alone classifier': 0.0}\n",
      "{'coverage': '92 out of2478', 'system accuracy': 85.0686037126715, 'expert accuracy': 84.82815718121063, 'classifier accuracy': 91.30424858233849, 'alone classifier': 0.0}\n",
      "[3.712671509281679, 85.0686037126715, 84.82815718121063, 91.30424858233849]\n",
      "{'coverage': '1 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.57811186288964, 'classifier accuracy': 99.9900009999, 'alone classifier': 0.0}\n",
      "{'coverage': '7 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 84.5811343924618, 'classifier accuracy': 99.9985714489793, 'alone classifier': 0.0}\n",
      "{'coverage': '22 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 84.60911363117967, 'classifier accuracy': 86.36324380343726, 'alone classifier': 0.0}\n",
      "{'coverage': '53 out of2478', 'system accuracy': 84.4229217110573, 'expert accuracy': 84.53607550217934, 'classifier accuracy': 79.2451334997481, 'alone classifier': 0.0}\n",
      "{'coverage': '186 out of2478', 'system accuracy': 85.51251008878127, 'expert accuracy': 84.77311651194447, 'classifier accuracy': 94.62360504107255, 'alone classifier': 0.0}\n",
      "{'coverage': '186 out of2478', 'system accuracy': 85.51251008878127, 'expert accuracy': 84.77311651194447, 'classifier accuracy': 94.62360504107255, 'alone classifier': 0.0}\n",
      "[7.506053268765133, 85.51251008878127, 84.77311651194447, 94.62360504107255]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.58433538463798, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '19 out of2478', 'system accuracy': 84.58434221146085, 'expert accuracy': 84.62789063620247, 'classifier accuracy': 78.94695291077416, 'alone classifier': 0.0}\n",
      "{'coverage': '129 out of2478', 'system accuracy': 85.35108958837772, 'expert accuracy': 84.88717880909503, 'classifier accuracy': 93.79837690048302, 'alone classifier': 0.0}\n",
      "{'coverage': '34 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 84.6562942179792, 'classifier accuracy': 82.3526989626501, 'alone classifier': 0.0}\n",
      "{'coverage': '88 out of2478', 'system accuracy': 84.98789346246973, 'expert accuracy': 84.72802638259193, 'classifier accuracy': 92.04534994846597, 'alone classifier': 0.0}\n",
      "{'coverage': '129 out of2478', 'system accuracy': 85.35108958837772, 'expert accuracy': 84.88717880909503, 'classifier accuracy': 93.79837690048302, 'alone classifier': 0.0}\n",
      "[5.2058111380145276, 85.35108958837772, 84.88717880909503, 93.79837690048302]\n",
      "{'coverage': '1837 out of2478', 'system accuracy': 92.49394673123487, 'expert accuracy': 87.20746108971574, 'classifier accuracy': 94.33859040072997, 'alone classifier': 0.0}\n",
      "{'coverage': '1386 out of2478', 'system accuracy': 89.7497982243745, 'expert accuracy': 84.52379404326116, 'classifier accuracy': 93.86723709471595, 'alone classifier': 0.0}\n",
      "{'coverage': '1032 out of2478', 'system accuracy': 88.90234059725586, 'expert accuracy': 85.40801031701102, 'classifier accuracy': 93.79844052340692, 'alone classifier': 0.0}\n",
      "{'coverage': '1165 out of2478', 'system accuracy': 90.23405972558515, 'expert accuracy': 85.52930913491103, 'classifier accuracy': 95.5364724861397, 'alone classifier': 0.0}\n",
      "{'coverage': '1089 out of2478', 'system accuracy': 89.50766747376917, 'expert accuracy': 85.45715112208048, 'classifier accuracy': 94.67400416216674, 'alone classifier': 0.0}\n",
      "{'coverage': '1837 out of2478', 'system accuracy': 92.49394673123487, 'expert accuracy': 87.20746108971574, 'classifier accuracy': 94.33859040072997, 'alone classifier': 0.0}\n",
      "[74.13236481033091, 92.49394673123487, 87.20746108971574, 94.33859040072997]\n"
     ]
    }
   ],
   "source": [
    "import copy, time \n",
    "for i in range(0,11):\n",
    "    model = CNN_rej(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 3, DROPOUT, PAD_IDX)\n",
    "\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    alpha = i/10\n",
    "    N_EPOCHS = 5\n",
    "\n",
    "    best_valid_loss = 0\n",
    "    best_model = None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_reject(model, train_iterator, optimizer, alpha)\n",
    "\n",
    "        valid_loss = metrics_print(model,valid_iterator)[1]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss >= best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "\n",
    "    print(metrics_print(best_model, valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmou1/scratchenalisn1/ziyao/anaconda3/envs/hs_legacy/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04741000461720767, 0.18181797520684634, 0.13440797058963866]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_fairness(best_model, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmou1/scratchenalisn1/ziyao/anaconda3/envs/hs_legacy/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '5441 out of7435', 'system accuracy': 93.30195023537324, 'expert accuracy': 87.5626792815768, 'classifier accuracy': 95.40525463324288, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[73.18090114324143, 93.30195023537324, 87.5626792815768, 95.40525463324288]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print(best_model, test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gL9zMseKV08"
   },
   "source": [
    "# Baseline: Confidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTpVIBmaTd0F"
   },
   "outputs": [],
   "source": [
    "class CNN_(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DW24ej8Kiog"
   },
   "source": [
    "## expert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wa26cku4KXn_"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_expert = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 2, DROPOUT, PAD_IDX)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model_expert.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model_expert.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model_expert.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xI84VYA_Kovo"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_expert.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_expert = model_expert.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpLZVhleKrd6"
   },
   "outputs": [],
   "source": [
    "def train_expert(model_exp, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model_exp.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model_exp(batch.text)\n",
    "\n",
    "        \n",
    "        loss = criterion(predictions, batch.expert)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.expert)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_expert(model_exp, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_exp.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model_exp(batch.text)\n",
    "            loss = criterion(predictions, batch.expert)\n",
    "            acc = categorical_accuracy(predictions, batch.expert)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "I0P9v_fnKu8x",
    "outputId": "bc853ec7-c1b7-4430-d138-d4ed12771bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.466 | Train Acc: 83.66%\n",
      "\t Val. Loss: 0.437 |  Val. Acc: 84.27%\n",
      "Epoch: 02 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.416 | Train Acc: 84.23%\n",
      "\t Val. Loss: 0.447 |  Val. Acc: 84.11%\n",
      "Epoch: 03 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.371 | Train Acc: 85.24%\n",
      "\t Val. Loss: 0.492 |  Val. Acc: 80.24%\n",
      "Epoch: 04 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.306 | Train Acc: 87.70%\n",
      "\t Val. Loss: 0.493 |  Val. Acc: 82.99%\n",
      "Epoch: 05 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.236 | Train Acc: 90.61%\n",
      "\t Val. Loss: 0.615 |  Val. Acc: 72.24%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_expert(model_expert, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate_expert(model_expert, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_expert.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2UHAGm-QW-I"
   },
   "source": [
    "## classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meGJ9JJXQKMo"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_class = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model_class.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model_class.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model_class.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_class.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_class = model_class.to(device)\n",
    "criterion = criterion.to(device)\n",
    "def train(model_class, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model_class.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model_class(batch.text)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate(model_class, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_class.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model_class(batch.text)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "vDJ68oaoQi3v",
    "outputId": "56617497-e5ef-4955-bf1d-f00109752210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.469 | Train Acc: 82.94%\n",
      "\t Val. Loss: 0.315 |  Val. Acc: 88.97%\n",
      "Epoch: 02 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.285 | Train Acc: 89.75%\n",
      "\t Val. Loss: 0.308 |  Val. Acc: 90.00%\n",
      "Epoch: 03 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.214 | Train Acc: 92.61%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 90.31%\n",
      "Epoch: 04 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.87%\n",
      "\t Val. Loss: 0.321 |  Val. Acc: 90.00%\n",
      "Epoch: 05 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.111 | Train Acc: 96.18%\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 89.57%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model_class, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model_class, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_class.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtNZ4bMAT2_8"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def metrics_print_confid(net_class, net_exp, loader):\n",
    "    net_class.eval()\n",
    "    net_exp.eval()\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            outputs_exp = net_exp(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                r_score = 1 - np.max(arr) #outputs_class.data[i][predicted[i].item()].item()\n",
    "                arr_exp = [outputs_exp.data[i][0].item(),outputs_exp.data[i][1].item()]\n",
    "                arr_exp = softmax(arr_exp)\n",
    "                r_score = r_score - arr_exp[0]\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys +=  data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "\n",
    "def metrics_print_confid_fairness(net_class, net_exp, loader):\n",
    "    net_class.eval()\n",
    "    net_exp.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            outputs_exp = net_exp(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                r_score = 1 - np.max(arr) #outputs_class.data[i][predicted[i].item()].item()\n",
    "                arr_exp = [outputs_exp.data[i][0].item(),outputs_exp.data[i][1].item()]\n",
    "                arr_exp = softmax(arr_exp)\n",
    "                r_score = r_score - arr_exp[0]\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                prediction = 0\n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "    print(group_1_counts)\n",
    "    print(group_0_counts)\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "M5sUm1NgVZrY",
    "outputId": "8e1ea87e-49af-4068-d7d7-9b73c98ef791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '6207 out of7435', 'system accuracy': 92.49495628782785, 'expert accuracy': 88.02930162389225, 'classifier accuracy': 93.37844218819974, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[83.48352387357095, 92.49495628782785, 88.02930162389225, 93.37844218819974]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_confid(model_class, model_expert,test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "1133\n",
      "{'group0': 0.09885259498211872, 'group1': 0.3555551604942661, 'discrimination': -0.2567025655121474}\n",
      "[0.09885259498211872, 0.3555551604942661, 0.2567025655121474]\n"
     ]
    }
   ],
   "source": [
    "print(metrics_print_confid_fairness(model_class, model_expert,test_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YzzfbXZ6aJH"
   },
   "source": [
    "# Oracle Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJf-zDG46cbU"
   },
   "outputs": [],
   "source": [
    "def metrics_print_oracle(net_class, loader):\n",
    "    # prints classification metrics for Oracle baseline\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= 0.90:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= 0.75:\n",
    "                        r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys +=  data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def metrics_print_oracle_fairness(net_class, loader):\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= 0.90:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= 0.75:\n",
    "                        r = 1                \n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_print_classifier(net_class, loader):\n",
    "    # print classification metrics of the classifier alone on all the dataset\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                total += 1\n",
    "                correct += (predicted[i] == data.label[i]).item()\n",
    "                correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "\n",
    "def metrics_print_classifier_fairness(net_class, loader):\n",
    "    # print fairness metrics of the classifier alone on all the dataset\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                prediction = predicted[i]\n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def metrics_print_expert_fairness( loader):\n",
    "    # print fairness metrics of the expert on all the dataset\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            batch_size =len(data)            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group0': 0.06266548431902169, 'group1': 0.11111098765445816, 'discrimination': -0.04844550333543647}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06266548431902169, 0.11111098765445816, 0.04844550333543647]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_expert_fairness( test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group0': 0.18358339068107762, 'group1': 0.4888883456796159, 'discrimination': -0.30530495499853827}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18358339068107762, 0.4888883456796159, 0.30530495499853827]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_classifier_fairness(model_class, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "h0QDnycBFWWB",
    "outputId": "d411364e-ec6e-4a89-bf79-8eedc5e4673a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '6188 out of7435', 'system accuracy': 93.6247478143914, 'expert accuracy': 88.77304109494129, 'classifier accuracy': 94.60245483835722, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[83.22797579018157, 93.6247478143914, 88.77304109494129, 94.60245483835722]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_oracle(model_class,test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.061782871863824196, 0.3777773580251577, 0.3159944861613335]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_oracle_fairness(model_class,test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: repeat data building for each expert type\n",
    "the following repeats the above code many times to obtain error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# build expert data\n",
    "all_data = train_data_orig[0]\n",
    "p = 0.75 # expert probability of being correct for AA tweeet\n",
    "q = 0.9 # expert probability of being correct for AA tweeet\n",
    "sum = 0\n",
    "total = 0\n",
    "i = 0\n",
    "aa_frac = 0\n",
    "for example in all_data:\n",
    "    lang = predict_lang(vars(example)['text'])\n",
    "    aa = 0\n",
    "    try:\n",
    "        if lang[0] >= 0.5:\n",
    "            aa = 1\n",
    "    except:\n",
    "        print(vars(example)['text'])\n",
    "    label = vars(example)['label']\n",
    "    exp = 0 # 0: expert wrong, 1: expert is right\n",
    "    exp_label = 0\n",
    "    if aa == 1: # if tweet is african american\n",
    "        #if label == '2':\n",
    "        #    exp = 0 # never predict neither\n",
    "        #else:\n",
    "        coin = np.random.binomial(1,p) \n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    else:\n",
    "        coin = np.random.binomial(1,q)\n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.long(label)\n",
    "        else:\n",
    "            exp_label = np.long(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    #if label =='2' : # 2: neither, 1: offensive, 0: hate speech\n",
    "    #    aa = 1\n",
    "    vars(all_data[i])['expertlabel'] = exp_label\n",
    "    vars(all_data[i])['group'] = str(aa)\n",
    "    vars(all_data[i])['expert'] = exp\n",
    "    aa_frac += aa\n",
    "    i += 1\n",
    "    total +=1\n",
    "    sum += exp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data  = all_data.split(split_ratio=[0.7,0.2,0.1])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be changed for each expert model\n",
    "def metrics_print_oracle(net_class, loader):\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= q:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= p:\n",
    "                        r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp +=  data.expert[i].item()\n",
    "                    correct_sys +=  data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def metrics_print_oracle_fairness(net_class, loader):\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= q:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= p:\n",
    "                        r = 1                \n",
    "                \n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_conf = []\n",
    "exp_rej = []\n",
    "exp_ora = []\n",
    "exp_conf_fairness = []\n",
    "exp_rej_fairness = []\n",
    "exp_ora_fairness = []\n",
    "max_trials = 1\n",
    "for exp in range(0,max_trials):\n",
    "    train_data, test_data, valid_data  = all_data.split(split_ratio=[0.6,0.1,0.3])\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), \n",
    "        sort = False,\n",
    "        batch_size = BATCH_SIZE, \n",
    "        device = device)\n",
    "    ##################################################################################################\n",
    "    ##################################################################################################\n",
    "    # baseline confidence\n",
    "    ##################################################################################################\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 300\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 2\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model_expert = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 2, DROPOUT, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model_expert.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model_expert.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model_expert.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model_expert.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_expert = model_expert.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = 5\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train_expert(model_expert, train_iterator, optimizer, criterion)\n",
    "        #valid_loss, valid_acc = evaluate_expert(model_expert, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # classifier\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 300\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 3\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model_class = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model_class.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model_class.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model_class.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    optimizer = optim.Adam(model_class.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_class = model_class.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = 5\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model_class, train_iterator, optimizer, criterion)\n",
    "        #valid_loss, valid_acc = evaluate(model_class, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    ####################################\n",
    "    print(\"Baseline\")\n",
    "    \n",
    "    conf = metrics_print_confid(model_class, model_expert,test_iterator)\n",
    "    exp_conf.append(conf)\n",
    "    conf = metrics_print_confid_fairness(model_class, model_expert,test_iterator)\n",
    "    exp_conf_fairness.append(conf)\n",
    "    ##################################################################################################\n",
    "    # my method \n",
    "    ##################################################################################################\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 1000\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 4\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 4, DROPOUT, PAD_IDX)\n",
    "\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    N_EPOCHS = 15\n",
    "\n",
    "    best_valid_loss = 0\n",
    "    best_model = None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_reject(model, train_iterator, optimizer, 1)\n",
    "        #train_loss, train_acc = train_reject_bla(model, train_iterator, optimizer)\n",
    "\n",
    "        #valid_loss, valid_acc = evaluate_reject(model, valid_iterator)\n",
    "        valid_loss = metrics_print(model,valid_iterator)[1]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss >= best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "    print(\"Our method\")\n",
    "    rej = metrics_print(best_model, test_iterator)\n",
    "    exp_rej.append(rej)\n",
    "    print(rej)\n",
    "    rej = metrics_print_fairness(best_model, test_iterator)\n",
    "    exp_rej_fairness.append(rej)\n",
    "    ##############################################################################################\n",
    "    # ORACLE\n",
    "    ora = metrics_print_oracle(model_class, test_iterator)\n",
    "    print(ora)\n",
    "    exp_ora.append(ora)\n",
    "    ora = metrics_print_oracle_fairness(model_class, test_iterator)\n",
    "    exp_ora_fairness.append(ora)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_class = [\"coverage\", \"system accuracy\", \"expert accuracy\", \"classifier accuracy\"]\n",
    "metrics_fairness = [\"FPR for group 0\", \"FPR for group 1\", \"discrimination\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Confidence Baseline\")\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_conf[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_conf_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Oracle Baseline\")\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_ora[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_ora_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for our method L_{CE}\")\n",
    "\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_rej[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_rej_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hatespeech - Faster Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "hs_legacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
